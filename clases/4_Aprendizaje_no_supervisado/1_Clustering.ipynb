{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHNQuIqAmvl5"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LinaMariaCastro/curso-ia-para-economia/blob/main/clases/4_Aprendizaje_no_supervisado/1_Clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iiwfbXCQv5D"
      },
      "source": [
        "# **Inteligencia Artificial con Aplicaciones en Econom√≠a I**\n",
        "\n",
        "- üë©‚Äçüè´ **Profesora:** [Lina Mar√≠a Castro](https://www.linkedin.com/in/lina-maria-castro)  \n",
        "- üìß **Email:** [lmcastroco@gmail.com](mailto:lmcastroco@gmail.com)  \n",
        "- üéì **Universidad:** Universidad Externado de Colombia - Facultad de Econom√≠a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfsUhkvVAwb_"
      },
      "source": [
        "# üîµüü¢üü† **An√°lisis de Clusters**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYgWrWp5_dDB"
      },
      "source": [
        "**Objetivos de Aprendizaje**\n",
        "\n",
        "Al finalizar este notebook, ser√°s capaz de:\n",
        "\n",
        "1.  **Entender la intuici√≥n econ√≥mica** detr√°s del an√°lisis de clustering y su aplicaci√≥n en la segmentaci√≥n de mercados.\n",
        "2. **Implementar** dos algoritmos de agrupamiento fundamentales: K-Means y K-prototypes.\n",
        "3. **Determinar el n√∫mero √≥ptimo de clusters** utilizando t√©cnicas como el M√©todo del Codo y el Coeficiente de Silueta.\n",
        "4. **Interpretar los resultados** de los algoritmos de clustering para extraer conclusiones de negocio y econ√≥micas valiosas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHjMtMi-ua1Y"
      },
      "source": [
        "**Introducci√≥n**\n",
        "\n",
        "Imagina que eres el gerente de un centro comercial. Tienes datos sobre tus clientes: cu√°nto ganan y cu√°nto gastan. Quieres lanzar campa√±as de marketing, pero enviar el mismo mensaje a todos es ineficiente. A un cliente que gana mucho y gasta poco (un ahorrador) no le interesar√° la misma promoci√≥n que a un cliente que gana poco pero gasta mucho (un entusiasta de las ofertas).\n",
        "\n",
        "El an√°lisis de clustering es una t√©cnica de machine learning no supervisado que nos permite hacer exactamente esto: descubrir grupos (o clusters) naturales en nuestros datos sin que nos digan previamente cu√°les son esos grupos. El algoritmo \"mira\" los datos y agrupa a los clientes que se parecen entre s√≠."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X84yTi9e_dDM"
      },
      "source": [
        "## Importar librer√≠as"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMPlxfM6CbaY"
      },
      "outputs": [],
      "source": [
        "# Importaci√≥n de librer√≠as est√°ndar\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Importaci√≥n de modelos y m√©tricas de Scikit-Learn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHE2ZLJuEPIe"
      },
      "source": [
        "## Mejorar visualizaci√≥n de dataframes y gr√°ficos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72TA8V1fETCm"
      },
      "outputs": [],
      "source": [
        "# Que muestre todas las columnas\n",
        "pd.options.display.max_columns = None\n",
        "# En los dataframes, mostrar los float con dos decimales\n",
        "pd.options.display.float_format = '{:,.2f}'.format\n",
        "\n",
        "# Configuraciones para una mejor visualizaci√≥n\n",
        "sns.set(style='whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDVWavcQ9zAW"
      },
      "source": [
        "## Cargar el dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYRaLbXlMc_c"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQSa_neuGLji"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/2025_ii_curso_ia_economia/datasets'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cka8EDXhQuee"
      },
      "outputs": [],
      "source": [
        "# Para establecer el directorio de los archivos\n",
        "os.chdir(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEjW10KsumIj"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('Mall_Customers.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qjy3l4pVxIom"
      },
      "outputs": [],
      "source": [
        "# Renombrar columnas para facilidad de uso\n",
        "df.rename(columns={\n",
        "    'Annual Income (k$)': 'Annual_Income',\n",
        "    'Spending Score (1-100)': 'Spending_Score'\n",
        "}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXL2821OvOXZ"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iwb4OAqMxKvF"
      },
      "outputs": [],
      "source": [
        "print(\"\\nEstad√≠sticas Descriptivas:\")\n",
        "print(df.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCGMBuKCxT8x"
      },
      "source": [
        "Los datos est√°n limpios (no hay nulos) y listos para el an√°lisis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmZ2USmtxfFs"
      },
      "source": [
        "## Visualizaci√≥n: ¬øPodemos \"Ver\" los Clusters?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_OHAcN6xcpV"
      },
      "source": [
        "La mejor forma de empezar es visualizando la relaci√≥n entre el ingreso anual y la puntuaci√≥n de gasto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gOOEQ9UxiTz"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='Annual_Income', y='Spending_Score', data=df)\n",
        "plt.title('Ingreso Anual vs. Puntuaci√≥n de Gasto')\n",
        "plt.xlabel('Ingreso Anual (en miles de $)')\n",
        "plt.ylabel('Puntuaci√≥n de Gasto (1-100)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRFdFeX4xp-g"
      },
      "source": [
        "A simple vista, podemos identificar 5 grupos de clientes. Esto es una gran ventaja, ya que nos da una hip√≥tesis clara para probar con nuestros algoritmos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKabOLPBxrB-"
      },
      "source": [
        "## Preprocesamiento: preparando los datos para el Clustering\n",
        "\n",
        "Para este an√°lisis, nos enfocaremos en las dos variables que visualizamos.\n",
        "\n",
        "Debido a que los algoritmos de clustering se basan en distancias, se deben estandarizar las variables para que ninguna domine a la otra solo por su escala."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7yWvHfGx-Kv"
      },
      "outputs": [],
      "source": [
        "# Seleccionamos las caracter√≠sticas para el clustering\n",
        "X = df[['Annual_Income', 'Spending_Score']]\n",
        "\n",
        "# Estandarizamos las caracter√≠sticas\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Convertimos a DataFrame para facilidad de uso posterior\n",
        "X_scaled_df = pd.DataFrame(X_scaled, columns=['Annual_Income', 'Spending_Score'])\n",
        "X_scaled_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8AKMwks-nMm"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(X)\n",
        "plt.suptitle('Pairplot de Datos Originales', y=1.02)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9tIbPX7-Trj"
      },
      "outputs": [],
      "source": [
        "# Generar un pairplot de los datos escalados\n",
        "sns.pairplot(X_scaled_df)\n",
        "plt.suptitle('Pairplot de Datos Estandarizados', y=1.02) # A√±adir un t√≠tulo general\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwD-yB1dyGWO"
      },
      "source": [
        "## K-Means"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSouxhrDyLFX"
      },
      "source": [
        "- K-Means es el algoritmo de clustering m√°s popular por su simplicidad y eficiencia.\n",
        "\n",
        "- Divide una muestra n en K clases.\n",
        "\n",
        "- Solo se aplica a variables num√©ricas.\n",
        "\n",
        "Pasos que sigue el algoritmo:\n",
        "\n",
        "1. El algoritmo asigna aleatoriamente 'k' puntos como centros de cada cluster (centroides).\n",
        "\n",
        "2. Asigna cada observaci√≥n al centroide m√°s cercano.\n",
        "\n",
        "3. Recalcula la posici√≥n de cada centroide como el promedio de todos los puntos asignados a √©l.\n",
        "\n",
        "4. Repite los pasos 2 y 3 hasta que los centroides ya no se mueven o hasta que se alcance el n√∫mero de iteraciones que le indiquemos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkd1PztxW4PE"
      },
      "outputs": [],
      "source": [
        "from IPython.display import YouTubeVideo\n",
        "\n",
        "# ID del video: https://www.youtube.com/watch?v=mICySHB0fh4\n",
        "YouTubeVideo('mICySHB0fh4', width=800, height=450)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlqK4WNh8acZ"
      },
      "source": [
        "**K-Means utiliza la Distancia Euclidiana**\n",
        "\n",
        "Es la que todos conocemos de la geometr√≠a. La distancia m√°s corta entre dos puntos: la hipotenusa de un tri√°ngulo.\n",
        "\n",
        "F√≥rmula:\n",
        "\n",
        "$$d(p, q) = \\sqrt{\\sum_{i=1}^{n} (p_i - q_i)^2}$$\n",
        "\n",
        "p y q: Son nuestros dos puntos (Cliente A y Cliente B).\n",
        "\n",
        "i: Es un √≠ndice que representa cada una de las dimensiones que estamos considerando (dimensi√≥n 1: Ingreso, dimensi√≥n 2: Gasto, dimensi√≥n 3: Edad, etc.).\n",
        "\n",
        "(pi‚àíqi): Es la diferencia entre los dos puntos a lo largo de una sola dimensi√≥n i.\n",
        "\n",
        "Ventajas:\n",
        "\n",
        "- Muy intuitiva y f√°cil de entender.\n",
        "- Funciona excelentemente cuando los clusters son compactos y esf√©ricos.\n",
        "\n",
        "Desventajas:\n",
        "\n",
        "- La Maldici√≥n de la Dimensionalidad: A medida que a√±adimos m√°s variables (dimensiones), la distancia euclidiana pierde significado. En un espacio de muchas dimensiones, la distancia entre cualquier par de puntos tiende a ser muy similar, dificultando la formaci√≥n de clusters densos.\n",
        "- Sensible a la escala de las variables (por eso siempre estandarizamos).\n",
        "\n",
        "Casos de Uso:\n",
        "- Segmentaci√≥n de clientes.\n",
        "- Agrupaci√≥n de acciones por retorno y volatilidad.\n",
        "- Agrupaci√≥n de establecimientos seg√∫n ventas y n√∫mero de clientes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bDZDghz91RU"
      },
      "source": [
        "### Aplicar K-Means y visualizar los resultados\n",
        "\n",
        "Ahora, aplicamos K-Means con k=5, seg√∫n lo que vimos en la gr√°fica."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJ6toBCX91RW"
      },
      "outputs": [],
      "source": [
        "# Aplicar K-Means con k=5\n",
        "kmeans = KMeans(n_clusters=5, init='k-means++', max_iter=300, n_init=10, random_state=42)\n",
        "clusters_kmeans = kmeans.fit_predict(X_scaled_df)\n",
        "clusters_kmeans\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kcwt8-IM5c7y"
      },
      "source": [
        "**Nota:**\n",
        "\n",
        "- init='k-means++': Es una forma 'inteligente' de elegir los centroides iniciales. En lugar de ponerlos al azar, este m√©todo trata de elegirlos lo m√°s separados posible entre s√≠. Esto hace que el algoritmo converja mucho m√°s r√°pido y a un mejor resultado. Es la opci√≥n por defecto y casi siempre la mejor.\n",
        "\n",
        "- n_init=10: K-Means puede a veces quedarse 'atrapado' en una soluci√≥n sub√≥ptima dependiendo de d√≥nde empezaron los centroides. Este par√°metro le dice a Scikit-Learn: 'Corre todo el algoritmo 10 veces desde el principio con diferentes centroides iniciales, y al final qu√©date con el mejor resultado de los 10'. Esto aumenta la probabilidad de encontrar la mejor soluci√≥n posible.\n",
        "\n",
        "- max_iter: Es el n√∫mero m√°ximo de iteraciones (ciclos de \"asignar puntos -> actualizar centroides\") que el algoritmo realizar√° en una sola ejecuci√≥n. Es una salvaguarda, ya que K-Means suele converger muy r√°pido (en menos de 100 iteraciones). Este l√≠mite evita que el algoritmo se ejecute indefinidamente si por alguna raz√≥n no converge. El valor por defecto es de 300 que es m√°s que suficiente para la gran mayor√≠a de los problemas. Rara vez necesitar√°s cambiarlo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ZgkBjvg91RX"
      },
      "outputs": [],
      "source": [
        "# A√±adir los clusters al DataFrame original\n",
        "df['Cluster_KMeans'] = clusters_kmeans\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KiKcOdg391RX"
      },
      "outputs": [],
      "source": [
        "# Ver las coordenadas de los centroides\n",
        "kmeans.cluster_centers_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6otLhYZ91RY"
      },
      "outputs": [],
      "source": [
        "# Visualizar los clusters\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.scatterplot(x='Annual_Income', y='Spending_Score', hue='Cluster_KMeans', data=df, palette='viridis', s=100)\n",
        "\n",
        "# Visualizar los centroides\n",
        "centroids = scaler.inverse_transform(kmeans.cluster_centers_)\n",
        "plt.scatter(centroids[:, 0], centroids[:, 1], s=300, c='red', marker='X', label='Centroides')\n",
        "\n",
        "plt.title('Segmentaci√≥n de Clientes con K-Means')\n",
        "plt.xlabel('Ingreso Anual (en miles de $)')\n",
        "plt.ylabel('Puntuaci√≥n de Gasto (1-100)')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGaGa_yCygbM"
      },
      "source": [
        "### Determinar el N√∫mero √ìptimo de Clusters (k)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsTbGpnK_zcR"
      },
      "source": [
        "#### Inercia\n",
        "\n",
        "Cuando entrenamos un modelo K-Means, el resultado tiene un atributo llamado inertia_. Este n√∫mero no es solo un resultado t√©cnico; **es el objetivo central que el algoritmo K-Means intenta minimizar**.\n",
        "\n",
        "En t√©rminos sencillos, **la inercia mide qu√© tan internamente coherentes y compactos son los clusters**. Un valor de inercia m√°s bajo significa que los clusters son m√°s densos y est√°n mejor definidos, ya que los puntos de datos est√°n, en promedio, m√°s cerca de sus respectivos centroides.\n",
        "\n",
        "Se calcula de la siguiente manera:\n",
        "\n",
        "1. Para cada punto de dato, medimos la distancia al centroide.\n",
        "2. Elevamos esa distancia al cuadrado. (Elevar al cuadrado penaliza m√°s fuertemente a los puntos que est√°n muy lejos).\n",
        "3. Sumamos los resultados de todos los puntos.\n",
        "\n",
        "El objetivo de K-Means es mover los centroides de tal manera que esta suma total de distancias al cuadrado sea la menor posible. Un valor de inercia bajo significa que logramos ubicar los centroides de forma muy eficiente, muy cerca de sus respectivos puntos de datos.\n",
        "\n",
        "La Definici√≥n Formal: WCSS\n",
        "\n",
        "El t√©rmino t√©cnico para la inercia es WCSS (Within-Cluster Sum of Squares) o \"Suma de Cuadrados Intra-Cluster\". La f√≥rmula es:\n",
        "\n",
        "$$\n",
        "\\text{Inercia (WCSS)} = \\sum_{j=1}^{k} \\sum_{i \\in C_j} \\| x_i - \\mu_j \\|^2\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tQJ_v6T91RY"
      },
      "outputs": [],
      "source": [
        "kmeans.inertia_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "py-dpSoz7fe-"
      },
      "source": [
        "#### M√©todo del Codo (Elbow Method)\n",
        "\n",
        "El m√©todo del codo **se basa enteramente en c√≥mo se comporta la inercia a medida que aumentamos el n√∫mero de clusters (k)**.\n",
        "\n",
        "- La inercia siempre disminuye con m√°s clusters: Esto es l√≥gico. En el caso extremo, si el n√∫mero de clusters es igual al n√∫mero de datos, la distancia de cada dato a su centroide ser√≠a cero y la inercia ser√≠a 0.\n",
        "\n",
        "- Por la raz√≥n anterior, no podemos simplemente elegir el k que nos d√© la menor inercia. Lo que buscamos es el \"codo\": el punto a partir del cual a√±adir un nuevo cluster ya no reduce la inercia de forma significativa. Es el punto donde el beneficio de a√±adir un nuevo cluster es marginal, lo que nos sugiere que hemos encontrado el n√∫mero de grupos \"naturales\" en los datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbwFR3oR5Q0J"
      },
      "outputs": [],
      "source": [
        "wcss = []\n",
        "for i in range(1, 11):\n",
        "    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=42)\n",
        "    kmeans.fit(X_scaled_df)\n",
        "    wcss.append(kmeans.inertia_)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(1, 11), wcss, marker='o', linestyle='--')\n",
        "plt.title('M√©todo del Codo')\n",
        "plt.xlabel('N√∫mero de Clusters (k)')\n",
        "plt.ylabel('WCSS')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "solQ0Gxl5dC1"
      },
      "source": [
        "El \"codo\" es claramente visible en k=5, confirmando nuestra intuici√≥n visual."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOrrJgEG5d4K"
      },
      "source": [
        "#### Coeficiente de Silueta (Silhouette Score)\n",
        "\n",
        "La idea central del Coeficiente de Silueta es responder dos preguntas para cada punto de dato individual:\n",
        "\n",
        "- ¬øQu√© tan bien encaja este punto en su propio cluster? (Cohesi√≥n)\n",
        "\n",
        "- ¬øQu√© tan mal encajar√≠a este punto en el siguiente cluster m√°s cercano? (Separaci√≥n)\n",
        "\n",
        "Un buen clustering es aquel en el que, para la mayor√≠a de los puntos, la respuesta a la primera pregunta es \"muy bien\" y la respuesta a la segunda es \"muy mal\".\n",
        "\n",
        "Para cada punto de dato i, calculamos dos valores:\n",
        "\n",
        "- a(i): **Cohesi√≥n Interna**. Es la distancia promedio de i a todos los dem√°s puntos dentro del mismo cluster. Un valor bajo de a(i) es bueno, significa que el punto est√° en un vecindario denso y coherente.\n",
        "\n",
        "- b(i): **Separaci√≥n Externa**. Es la distancia promedio de i a todos los puntos en el siguiente cluster m√°s cercano. El \"siguiente cluster m√°s cercano\" es aquel cuya distancia promedio desde i es la m√°s baja entre todos los clusters de los que i no es miembro. Un valor alto de b(i) es bueno, significa que los otros clusters est√°n lejos.\n",
        "\n",
        "Una vez que tenemos a(i) y b(i) para un solo punto i, la f√≥rmula del coeficiente de silueta para ese punto es:\n",
        "\n",
        "$$\n",
        "s(i) = \\frac{b(i) - a(i)}{\\max(a(i), b(i))}\n",
        "$$\n",
        "\n",
        "El Numerador (b(i) - a(i)): Es el coraz√≥n del c√°lculo. Queremos que la separaci√≥n b(i) sea lo m√°s grande posible y que la cohesi√≥n a(i) sea lo m√°s peque√±a posible. Por lo tanto, un valor grande y positivo en el numerador es ideal.\n",
        "\n",
        "El Denominador max(a(i), b(i)): Es un factor de normalizaci√≥n. Divide el resultado por el valor m√°s grande entre a(i) y b(i) para asegurar que el puntaje final siempre est√© entre -1 y 1.\n",
        "\n",
        "- **Puntaje cercano a +1** (Ideal ‚ú®): El punto est√° muy bien agrupado. Su propio cluster es muy denso y est√° muy lejos del siguiente cluster m√°s cercano.\n",
        "\n",
        "- **Puntaje cercano a 0** (Ambiguo üòê): El punto est√° en la frontera entre dos clusters. Est√° casi a la misma distancia de su propio cluster que del vecino. Esto indica que los clusters se superponen o que el punto podr√≠a pertenecer a cualquiera de los dos.\n",
        "\n",
        "- **Puntaje cercano a -1** (P√©simo ‚ùå): El punto probablemente ha sido asignado al cluster equivocado. En promedio, est√° m√°s cerca de los puntos de un cluster vecino que de los puntos de su propio cluster. Es una fuerte se√±al de que la estructura del clustering es incorrecta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VK0hTR2R5iNB"
      },
      "outputs": [],
      "source": [
        "# Se define un rango de valores para el n√∫mero de clusters (k) que vamos a probar.\n",
        "# Empezamos en 2 porque el coeficiente de silueta no se puede calcular para un solo cluster (k=1).\n",
        "# Probaremos desde k=2 hasta k=10.\n",
        "range_n_clusters = range(2, 11)\n",
        "\n",
        "silhouette_avg_scores = []\n",
        "\n",
        "for n_clusters in range_n_clusters:\n",
        "    clusterer = KMeans(n_clusters=n_clusters, n_init=10, random_state=42)\n",
        "    cluster_labels = clusterer.fit_predict(X_scaled_df)\n",
        "    silhouette_avg = silhouette_score(X_scaled_df, cluster_labels)\n",
        "    silhouette_avg_scores.append(silhouette_avg)\n",
        "    print(f\"Para n_clusters = {n_clusters}, el coeficiente de silueta promedio es: {silhouette_avg:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range_n_clusters, silhouette_avg_scores, marker='o', linestyle='--')\n",
        "plt.title('Coeficiente de Silueta para Varios k')\n",
        "plt.xlabel('N√∫mero de Clusters (k)')\n",
        "plt.ylabel('Coeficiente de Silueta Promedio')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6vrjK4r5r2r"
      },
      "source": [
        "El coeficiente de silueta m√°s alto tambi√©n se obtiene para k=5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8pAjoOE6i7G"
      },
      "source": [
        " **Nota:**\n",
        "\n",
        " Un puntaje promedio cercano a 1 indica que los clusters son densos y est√°n bien separados. Si es cercano a 0 o negativo, la estructura es d√©bil."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwAU-Qses42Z"
      },
      "outputs": [],
      "source": [
        "# Aplicar K-Means con k=5\n",
        "kmeans = KMeans(n_clusters=5, init='k-means++', max_iter=300, n_init=10, random_state=42)\n",
        "clusters_kmeans = kmeans.fit_predict(X_scaled_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Dcn3TPqs42d"
      },
      "outputs": [],
      "source": [
        "# Visualizar los clusters\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.scatterplot(x='Annual_Income', y='Spending_Score', hue='Cluster_KMeans', data=df, palette='viridis', s=100)\n",
        "\n",
        "# Visualizar los centroides\n",
        "centroids = scaler.inverse_transform(kmeans.cluster_centers_)\n",
        "plt.scatter(centroids[:, 0], centroids[:, 1], s=300, c='red', marker='X', label='Centroides')\n",
        "\n",
        "plt.title('Segmentaci√≥n de Clientes con K-Means')\n",
        "plt.xlabel('Ingreso Anual (en miles de $)')\n",
        "plt.ylabel('Puntuaci√≥n de Gasto (1-100)')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLjcrRCY6Aan"
      },
      "source": [
        "### Interpretaci√≥n de los Clusters (¬°La parte m√°s importante!)\n",
        "\n",
        "Ahora, le damos un significado a cada grupo:\n",
        "\n",
        "- **Cluster 0 (P√∫rpura): Promedio.** Ingresos y gastos medios. Representan al cliente general del centro comercial. Estrategia: Promociones generales, programas de lealtad.\n",
        "\n",
        "- **Cluster 1 (Azul Oscuro): Objetivo Principal.** ¬°El grupo so√±ado! Ingresos altos y puntuaci√≥n de gasto alta. Son los clientes m√°s rentables. Estrategia: Programas VIP, acceso anticipado a productos, marketing de lujo.\n",
        "\n",
        "- **Cluster 2 (Azul claro): J√≥venes Entusiastas.** Ingresos bajos, pero gastan mucho. Probablemente j√≥venes, sensibles a las tendencias y ofertas. Estrategia: Marketing en redes sociales, descuentos por tiempo limitado.\n",
        "\n",
        "- **Cluster 3 (Verde): Ahorradores Prudentes.** Ingresos altos, pero puntuaci√≥n de gasto baja. Son clientes valiosos pero dif√≠ciles de atraer. Estrategia: Marketing enfocado en calidad, durabilidad e inversi√≥n a largo plazo.\n",
        "\n",
        "- **Cluster 4 (Amarillo): Cautelosos.** Bajos ingresos y bajo gasto. Son muy sensibles al precio. Estrategia: Promociones de \"compre uno, lleve otro\", cupones de descuento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VYi99fbrz5T"
      },
      "outputs": [],
      "source": [
        "df.groupby('Cluster_KMeans')[['Annual_Income', 'Spending_Score', 'Age']].mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZTVXNty6_0n"
      },
      "source": [
        "## ¬øPodemos usar clustering para predecir algo? Por ejemplo, ¬øpredecir a qu√© cluster pertenecer√° un nuevo cliente?\n",
        "\n",
        "Una vez que has creado tus clusters y est√°s satisfecho con ellos, la etiqueta del cluster (Cluster_KMeans en nuestro notebook) se convierte en una nueva variable objetivo. Luego, puedes entrenar un modelo de clasificaci√≥n (como una regresi√≥n log√≠stica o un √°rbol de decisi√≥n) para predecir la probabilidad de que un nuevo cliente, bas√°ndose en su edad, ingreso, etc., pertenezca a uno de tus segmentos definidos. Esto es extremadamente √∫til para la toma de decisiones en tiempo real."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYaBbXdjx1Y_"
      },
      "source": [
        "## Clustering Avanzado: Manejo de Variables Categ√≥ricas con K-Prototypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiA71Obsx5Ks"
      },
      "source": [
        "Hasta ahora, hemos trabajado principalmente con variables num√©ricas (Annual_Income, Spending_Score). Pero, ¬øqu√© pasa con la columna Gender? ¬øPodemos incluirla en nuestro an√°lisis para obtener segmentos a√∫n m√°s ricos?\n",
        "\n",
        "Los algoritmos como K-Means, que se basan en la distancia euclidiana, no pueden manejar texto como \"Male\" o \"Female\" directamente. Para resolver esto, podemos emplear modelos como K-Prototypes para datos mixtos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUF7COLI7OP2"
      },
      "outputs": [],
      "source": [
        "#!pip install kmodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9wZDeYnyZdV"
      },
      "outputs": [],
      "source": [
        "# Importamos los nuevos algoritmos\n",
        "from kmodes.kmodes import KModes\n",
        "from kmodes.kprototypes import KPrototypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WG2HiFrmzpQG"
      },
      "source": [
        "K-Prototypes, en lugar de \"centroides\", crea \"prototipos\" de clusters que son un h√≠brido:\n",
        "\n",
        "- Para las columnas num√©ricas, el prototipo es la media.\n",
        "\n",
        "- Para las columnas categ√≥ricas, el prototipo es la moda.\n",
        "\n",
        "La distancia total es una combinaci√≥n ponderada de la distancia euclidiana y la de Hamming."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXZh6-doAdhq"
      },
      "source": [
        "**Nota: Distancia de Hamming**\n",
        "\n",
        "Se cuenta el n√∫mero de variables en las que son diferentes dos observaciones: Un cliente ['M√≥vil', 'Chrome', 'S√≠'] tendr√≠a una distancia de 0 con otro cliente id√©ntico, y una distancia de 3 con un cliente ['PC', 'Firefox', 'No']."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvSqNBYy_q19"
      },
      "source": [
        "\n",
        "Vamos a segmentar a nuestros clientes usando Age, Annual_Income, Spending_Score y, ahora tambi√©n, Gender."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWk-EeSF3yLc"
      },
      "outputs": [],
      "source": [
        "# Hacemos una copia del DataFrame para este an√°lisis\n",
        "df_mixed = df[['Age', 'Annual_Income', 'Spending_Score', 'Gender']].copy()\n",
        "df_mixed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "reKvaPV0zdKd"
      },
      "outputs": [],
      "source": [
        "# El algoritmo necesita saber la posici√≥n de las columnas categ√≥ricas.\n",
        "# En nuestro caso, 'Gender' est√° en la √∫ltima posici√≥n (√≠ndice 3).\n",
        "categorical_columns_index = [3]\n",
        "\n",
        "# Convertimos los datos a una matriz numpy\n",
        "data_matrix = df_mixed.values\n",
        "\n",
        "# K-Prototypes es sensible a la escala, por lo que estandarizamos las variables num√©ricas primero\n",
        "# Nota: Estandarizamos solo las columnas num√©ricas (0, 1, 2)\n",
        "scaler = StandardScaler()\n",
        "data_matrix[:, 0:3] = scaler.fit_transform(data_matrix[:, 0:3])\n",
        "\n",
        "# La columna 'Gender' tambi√©n debe ser codificada num√©ricamente para el algoritmo\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "data_matrix[:, 3] = le.fit_transform(data_matrix[:, 3])\n",
        "print(f\"El mapeo de clases es: {le.classes_}\")\n",
        "\n",
        "# Aplicamos K-Prototypes\n",
        "kproto = KPrototypes(n_clusters=5, init='Cao', n_init=5, verbose=0, random_state=42)\n",
        "clusters_kproto = kproto.fit_predict(data_matrix, categorical=categorical_columns_index)\n",
        "clusters_kproto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vr0BpeE4IDf"
      },
      "outputs": [],
      "source": [
        "# A√±adimos los clusters al DataFrame original\n",
        "df_mixed['Cluster_KPrototypes'] = clusters_kproto\n",
        "df_mixed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-kA8T_WC0SfC"
      },
      "outputs": [],
      "source": [
        "print(kproto.cluster_centroids_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWQ8asEY0YpN"
      },
      "outputs": [],
      "source": [
        "# Analicemos el perfil de los clusters con los datos originales\n",
        "print(\"\\nPerfil de los clusters (medias y modas):\")\n",
        "df_mixed.groupby('Cluster_KPrototypes').agg({\n",
        "    'Age': 'mean',\n",
        "    'Annual_Income': 'mean',\n",
        "    'Spending_Score': 'mean',\n",
        "    'Gender': lambda x: x.mode()[0]  # Calculamos la moda para el g√©nero\n",
        "}).round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DY9_9_s0lOg"
      },
      "source": [
        "Ahora tenemos una segmentaci√≥n mucho m√°s rica:\n",
        "\n",
        "- Cluster 0: Hombres de mediana edad, Cautelosos. Edad promedio mediana (~41 a√±os), ingresos altos y gastos bajos.\n",
        "\n",
        "- Cluster 1: Mujeres J√≥venes, Alto Poder Adquisitivo (Objetivo Principal). Edad promedio ~33 a√±os, ingresos y gastos muy altos. Este es el segmento premium.\n",
        "\n",
        "- Cluster 2: Mujeres de Mediana Edad, Ahorradoras. Edad promedio ~46 a√±os, bajos ingresos y bajo gasto.\n",
        "\n",
        "- Cluster 3: Mujeres muy J√≥venes, Entusiastas. Edad promedio muy baja (~25 a√±os), bajos ingresos pero alto gasto.\n",
        "\n",
        "- Cluster 4: Mujeres de Mediana Edad, Promedio. Edad promedio mediana (~55 a√±os), ingresos y gastos en el rango medio.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zW2TUFM0vit"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "sns.scatterplot(x='Annual_Income', y='Spending_Score', hue='Cluster_KPrototypes', data=df_mixed, palette='tab10', s=100)\n",
        "# 1. Extraemos solo la parte num√©rica de los prototipos (Age, Annual_Income, Spending_Score)\n",
        "# kproto.cluster_centroids_ contiene tanto las medias num√©ricas como las modas categ√≥ricas.\n",
        "# Seleccionamos las primeras 3 columnas que corresponden a nuestras variables num√©ricas.\n",
        "numeric_prototypes = kproto.cluster_centroids_[:, 0:3]\n",
        "\n",
        "# 2. Aplicamos la transformaci√≥n inversa para devolver los centroides a su escala original.\n",
        "# Usamos el mismo objeto 'scaler' que utilizamos para entrenar el modelo.\n",
        "prototypes_original_scale = scaler.inverse_transform(numeric_prototypes)\n",
        "\n",
        "# 3. Graficamos los prototipos (centroides) sobre el scatter plot.\n",
        "# Extraemos las coordenadas correspondientes a 'Annual_Income' (√≠ndice 1) y 'Spending_Score' (√≠ndice 2).\n",
        "plt.scatter(\n",
        "    prototypes_original_scale[:, 1],  # Coordenada X: Ingreso Anual\n",
        "    prototypes_original_scale[:, 2],  # Coordenada Y: Puntuaci√≥n de Gasto\n",
        "    s=300,                            # Tama√±o del marcador\n",
        "    c='red',                          # Color\n",
        "    marker='X',                       # Forma del marcador\n",
        "    label='Prototipos'                # Etiqueta para la leyenda\n",
        ")\n",
        "\n",
        "# Actualizamos la leyenda para incluir los prototipos\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iw20O_YI9a91"
      },
      "source": [
        "### B√∫squeda del K √≥ptimo para K-Prototypes: se utiliza el m√©todo del codo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYPIKEVD9YaC"
      },
      "outputs": [],
      "source": [
        "# Lista para almacenar los costos para cada valor de k\n",
        "costs = []\n",
        "# Rango de clusters que vamos a probar\n",
        "range_n_clusters = range(2, 11)\n",
        "\n",
        "print(\"Calculando el costo para cada valor de k...\")\n",
        "\n",
        "# Bucle para probar diferentes n√∫meros de clusters\n",
        "for k in range_n_clusters:\n",
        "    # Creamos una instancia de KPrototypes para el k actual\n",
        "    kproto = KPrototypes(n_clusters=k, init='Cao', n_init=5, verbose=0, random_state=42)\n",
        "\n",
        "    # Entrenamos el modelo con nuestros datos mixtos y especificamos las columnas categ√≥ricas\n",
        "    kproto.fit(data_matrix, categorical=categorical_columns_index)\n",
        "\n",
        "    # Guardamos el costo (la 'inercia' de K-Prototypes) en nuestra lista\n",
        "    costs.append(kproto.cost_)\n",
        "\n",
        "    print(f\"Costo para k={k}: {kproto.cost_:.2f}\")\n",
        "\n",
        "# Graficamos el m√©todo del codo\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range_n_clusters, costs, marker='o', linestyle='--')\n",
        "plt.title('M√©todo del Codo para K-Prototypes')\n",
        "plt.xlabel('N√∫mero de Clusters (k)')\n",
        "plt.ylabel('Costo del Clustering')\n",
        "plt.xticks(range_n_clusters)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
